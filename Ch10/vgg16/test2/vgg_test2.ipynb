{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from PIL import Image\n",
    "# import matplotlib as pltall\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# VGG 自带的一个常量，之前VGG训练通过归一化，所以现在同样需要作此操作\n",
    "VGG_MEAN = [103.939, 116.779, 123.68]  # rgb 三通道的均值\n",
    "\n",
    "\n",
    "class VGGNet():\n",
    "    '''\n",
    "    创建 vgg16 网络 结构\n",
    "    从模型中载入参数\n",
    "    '''\n",
    "\n",
    "    def __init__(self, data_dict):\n",
    "        '''\n",
    "        传入vgg16模型\n",
    "        :param data_dict: vgg16.npy (字典类型)\n",
    "        对象方法的第一个参数默认指向调用这个方法的对象# 哪个对象调用这个方法，\n",
    "        self就会指向这个对象# self不是关键字，可以改成别的变量名，但是不建议这样做\n",
    "        '''\n",
    "        self.data_dict = data_dict\n",
    "\n",
    "    def get_conv_filter(self, name):\n",
    "        '''\n",
    "        得到对应名称的卷积层\n",
    "        :param name: 卷积层名称\n",
    "        :return: 该卷积层输出\n",
    "        '''\n",
    "        return tf.constant(self.data_dict[name][0], name='conv')\n",
    "\n",
    "    def get_fc_weight(self, name):\n",
    "        '''\n",
    "        获得名字为name的全连接层权重\n",
    "        :param name: 连接层名称\n",
    "        :return: 该层权重\n",
    "        '''\n",
    "        return tf.constant(self.data_dict[name][0], name='fc')\n",
    "\n",
    "    def get_bias(self, name):\n",
    "        '''\n",
    "        获得名字为name的全连接层偏置\n",
    "        :param name: 连接层名称\n",
    "        :return: 该层偏置\n",
    "        '''\n",
    "        return tf.constant(self.data_dict[name][1], name='bias')\n",
    "\n",
    "    def conv_layer(self, x, name):\n",
    "        '''\n",
    "        创建一个卷积层\n",
    "        :param x:\n",
    "        :param name:\n",
    "        :return:\n",
    "        '''\n",
    "        # 在写计算图模型的时候，加一些必要的 name_scope，这是一个比较好的编程规范\n",
    "        # 可以防止命名冲突， 二可视化计算图的时候比较清楚\n",
    "        with tf.name_scope(name):\n",
    "            # 获得 w 和 b\n",
    "            conv_w = self.get_conv_filter(name)\n",
    "            conv_b = self.get_bias(name)\n",
    "\n",
    "            # 进行卷积计算\n",
    "            h = tf.nn.conv2d(x, conv_w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "            '''\n",
    "            因为此刻的 w 和 b 是从外部传递进来，所以使用 tf.nn.conv2d()\n",
    "            tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu = None, name = None) 参数说明：\n",
    "            input 输入的tensor， 格式[batch, height, width, channel]\n",
    "            filter 卷积核 [filter_height, filter_width, in_channels, out_channels] \n",
    "                分别是：卷积核高，卷积核宽，输入通道数，输出通道数\n",
    "            strides 步长 卷积时在图像每一维度的步长，长度为4\n",
    "            padding 参数可选择 “SAME” “VALID”\n",
    "\n",
    "            '''\n",
    "            # 加上偏置\n",
    "            h = tf.nn.bias_add(h, conv_b)\n",
    "            # 使用激活函数\n",
    "            h = tf.nn.relu(h)\n",
    "            return h\n",
    "\n",
    "    def pooling_layer(self, x, name):\n",
    "        '''\n",
    "        创建池化层\n",
    "        :param x: 输入的tensor\n",
    "        :param name: 池化层名称\n",
    "        :return: tensor\n",
    "        '''\n",
    "        return tf.nn.max_pool(x,\n",
    "                              ksize=[1, 2, 2, 1],  # 核参数， 注意：都是4维\n",
    "                              strides=[1, 2, 2, 1],\n",
    "                              padding='SAME',\n",
    "                              name=name\n",
    "                              )\n",
    "\n",
    "    def fc_layer(self, x, name, activation=tf.nn.relu):\n",
    "        '''\n",
    "        创建全连接层\n",
    "        :param x: 输入tensor\n",
    "        :param name: 全连接层名称\n",
    "        :param activation: 激活函数名称\n",
    "        :return: 输出tensor\n",
    "        '''\n",
    "        with tf.name_scope(name, activation):\n",
    "            # 获取全连接层的 w 和 b\n",
    "            fc_w = self.get_fc_weight(name)\n",
    "            fc_b = self.get_bias(name)\n",
    "            # 矩阵相乘 计算\n",
    "            h = tf.matmul(x, fc_w)\n",
    "            # 　添加偏置\n",
    "            h = tf.nn.bias_add(h, fc_b)\n",
    "            # 因为最后一层是没有激活函数relu的，所以在此要做出判断\n",
    "            if activation is None:\n",
    "                return h\n",
    "            else:\n",
    "                return activation(h)\n",
    "\n",
    "    def flatten_layer(self, x, name):\n",
    "        '''\n",
    "        展平\n",
    "        :param x: input_tensor\n",
    "        :param name:\n",
    "        :return: 二维矩阵\n",
    "        '''\n",
    "        with tf.name_scope(name):\n",
    "            # [batch_size, image_width, image_height, channel]\n",
    "            x_shape = x.get_shape().as_list()\n",
    "            # 计算后三维合并后的大小\n",
    "            dim = 1\n",
    "            for d in x_shape[1:]:\n",
    "                dim *= d\n",
    "            # 形成一个二维矩阵\n",
    "            x = tf.reshape(x, [-1, dim])\n",
    "            return x\n",
    "\n",
    "    def build(self, x_rgb):\n",
    "        '''\n",
    "        创建vgg16 网络\n",
    "        :param x_rgb: [1, 224, 224, 3],即输入图像的四维矩阵\n",
    "        :return:\n",
    "        '''\n",
    "        start_time = time.time()\n",
    "        print('model is creating')\n",
    "        # 将输入图像进行处理，将每个通道减去均值\n",
    "        r, g, b = tf.split(x_rgb, [1, 1, 1], axis=3)\n",
    "        print (r.shape)\n",
    "        '''\n",
    "        tf.split(value, num_or_size_split, axis=0)用法：\n",
    "        value:输入的Tensor\n",
    "        num_or_size_split:有两种用法：\n",
    "            1.直接传入一个整数，代表会被切成几个张量，切割的维度有axis指定\n",
    "            2.传入一个向量，向量长度就是被切的份数。传入向量的好处在于，可以指定每一份有多少元素\n",
    "        axis, 指定从哪一个维度切割\n",
    "        因此，上一句的意思就是从第4维切分，分为3份，每一份只有1个元素\n",
    "        结果就是把三个通道的数据分成了三个张量（单通道的二维数组）\n",
    "        '''\n",
    "        # 将 处理后的通道再次合并起来\n",
    "        x_bgr = tf.concat([b - VGG_MEAN[0], g - VGG_MEAN[1], r - VGG_MEAN[2]], axis=3)\n",
    "\n",
    "        #        assert x_bgr.get_shape().as_list()[1:] == [224, 224, 3]\n",
    "\n",
    "        # 开始构建卷积层\n",
    "        # vgg16 的网络结构\n",
    "        # 第一层：2个卷积层 1个pooling层\n",
    "        # 第二层：2个卷积层 1个pooling层\n",
    "        # 第三层：3个卷积层 1个pooling层\n",
    "        # 第四层：3个卷积层 1个pooling层\n",
    "        # 第五层：3个卷积层 1个pooling层\n",
    "        # 第六层： 全连接\n",
    "        # 第七层： 全连接\n",
    "        # 第八层： 全连接\n",
    "\n",
    "        # 这些变量名称不能乱取，必须要和vgg16模型保持一致\n",
    "        # 另外，将这些卷积层用self.的形式，方便以后取用方便\n",
    "        self.conv1_1 = self.conv_layer(x_bgr, 'conv1_1')\n",
    "        self.conv1_2 = self.conv_layer(self.conv1_1, 'conv1_2')\n",
    "        self.pool1 = self.pooling_layer(self.conv1_2, 'pool1')\n",
    "\n",
    "        self.conv2_1 = self.conv_layer(self.pool1, 'conv2_1')\n",
    "        self.conv2_2 = self.conv_layer(self.conv2_1, 'conv2_2')\n",
    "        self.pool2 = self.pooling_layer(self.conv2_2, 'pool2')\n",
    "\n",
    "        self.conv3_1 = self.conv_layer(self.pool2, 'conv3_1')\n",
    "        self.conv3_2 = self.conv_layer(self.conv3_1, 'conv3_2')\n",
    "        self.conv3_3 = self.conv_layer(self.conv3_2, 'conv3_3')\n",
    "        self.pool3 = self.pooling_layer(self.conv3_3, 'pool3')\n",
    "\n",
    "        self.conv4_1 = self.conv_layer(self.pool3, 'conv4_1')\n",
    "        self.conv4_2 = self.conv_layer(self.conv4_1, 'conv4_2')\n",
    "        self.conv4_3 = self.conv_layer(self.conv4_2, 'conv4_3')\n",
    "        self.pool4 = self.pooling_layer(self.conv4_3, 'pool4')\n",
    "\n",
    "        self.conv5_1 = self.conv_layer(self.pool4, 'conv5_1')\n",
    "        self.conv5_2 = self.conv_layer(self.conv5_1, 'conv5_2')\n",
    "        self.conv5_3 = self.conv_layer(self.conv5_2, 'conv5_3')\n",
    "        self.pool5 = self.pooling_layer(self.conv5_3, 'pool5')\n",
    "\n",
    "        print('model was created | cost：%4ds' % (time.time() - start_time))\n",
    "        print('use model to get image feture......')\n",
    "\n",
    "\n",
    "\n",
    "# 指定 model 路径\n",
    "vgg16_npy_pyth = './vgg16.npy'\n",
    "# 内容图像 路径\n",
    "content_img_path = './images/1018-1.jpg'\n",
    "all_img_path='./images'\n",
    "\n",
    "\n",
    "def read_img(img_name):\n",
    "    '''\n",
    "    读取图片\n",
    "    :param img_name: 图片路径\n",
    "    :return: 4维矩阵\n",
    "    '''\n",
    "    img = Image.open(img_name)\n",
    "    np_img = np.array(img) # 224, 224, 3\n",
    "    # 需要传化 成 4 维\n",
    "    np_img = np.asarray([np_img], dtype = np.int32) # 这个函数作用不太理解 (1, 224, 224, 3)\n",
    "    return np_img\n",
    "\n",
    "\n",
    "\n",
    "def get_row_col(num_pic):\n",
    "    '''\n",
    "    计算行列的值\n",
    "    :param num_pic: 特征图的数量\n",
    "    :return:\n",
    "    '''\n",
    "    squr = num_pic ** 0.5\n",
    "    row = round(squr)\n",
    "    col = row + 1 if squr - row > 0 else row\n",
    "    return row, col\n",
    "\n",
    "def visualize_feature_map(feature_batch):\n",
    "    '''\n",
    "    创建特征子图，创建叠加后的特征图\n",
    "    :param feature_batch: 一个卷积层所有特征图\n",
    "    :return:\n",
    "    '''\n",
    "    feature_map = np.squeeze(feature_batch, axis=0)\n",
    "\n",
    "    feature_map_combination = []\n",
    "    plt.figure(figsize=(8, 7))\n",
    "\n",
    "    # 取出 featurn map 的数量，因为特征图数量很多，这里直接手动指定了。\n",
    "    #num_pic = feature_map.shape[2]\n",
    "\n",
    "    row, col = get_row_col(25)\n",
    "    # 将 每一层卷积的特征图，拼接层 5 × 5\n",
    "    for i in range(0, 25):\n",
    "        feature_map_split = feature_map[:, :, i]\n",
    "        feature_map_combination.append(feature_map_split)\n",
    "        plt.subplot(row, col, i+1)\n",
    "        plt.imshow(feature_map_split)\n",
    "        plt.axis('off')\n",
    "\n",
    "    #plt.savefig('./mao_feature/feature_map2.png') # 保存图像到本地\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def visualize_feature_map_sum(feature_batch):\n",
    "    '''\n",
    "    将每张子图进行相加\n",
    "    :param feature_batch:\n",
    "    :return:\n",
    "    '''\n",
    "    #去掉0维的数据[1,9,9,512]变成[9,9,512]\n",
    "    # 用法：numpy.squeeze(a,axis = None)\n",
    "    # a表示输入的数组；\n",
    "    # axis用于指定需要删除的维度，但是指定的维度必须为单维度，否则将会报错；\n",
    "    # axis的取值可为None 或 int 或 tuple of ints, 可选。若axis为空，则删除所有单维度的条目；\n",
    "    # 返回值：数组\n",
    "    # 不会修改原数组；\n",
    "    feature_map = np.squeeze(feature_batch, axis=0)\n",
    "\n",
    "    feature_map_combination = []\n",
    "\n",
    "    # 取出 featurn map 的数量,即第三维的值512\n",
    "    num_pic = feature_map.shape[2]\n",
    "\n",
    "    # 将 每一层卷积的特征图，拼接层 5 × 5\n",
    "    # 从0到512遍历\n",
    "    for i in range(0, num_pic):\n",
    "        '''\n",
    "        [:,:,i]取所有第二维的第i列数据拿出来，列变行组成一个新的矩阵，返回的结果是一个二维矩阵\n",
    "        可参考下面cell的实例\n",
    "        '''\n",
    "        feature_map_split = feature_map[:, :, i]\n",
    "        \n",
    "        #shape:[512,5,5]\n",
    "        feature_map_combination.append(feature_map_split)\n",
    "\n",
    "    # 按照特征图 进行 叠加代码\n",
    "    # feature_map_combination所有项进行求和，叠加成一个[5,5]的二维矩阵\n",
    "    feature_map_sum = sum(one for one in feature_map_combination)\n",
    "\n",
    "    print(\"what??\")\n",
    "    #显示灰度图\n",
    "    plt.imshow(feature_map_sum)\n",
    "    #plt.savefig('./mao_feature/feature_map_sum2.png') # 保存图像到本地\n",
    "#     pltall.use('TkAgg')\n",
    "    #这句干嘛用的\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 4]\n",
      "[[ 1  3  5]\n",
      " [15  2 99]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0,1],[2,3],[4,5]])  \n",
    "print(X[:,0])\n",
    "y = np.array([[[0,1],[2,3],[4,5]],[[12,15],[19,2],[22,99]]])\n",
    "print(y[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641-6.jpg\n",
      "./images/641-6.jpg\n",
      "(1, 66, 67, 3)\n",
      "(1, 66, 67, 3)\n",
      "model is creating\n",
      "(1, 66, 67, 1)\n",
      "model was created | cost：   0s\n",
      "use model to get image feture......\n",
      "(1, 66, 67, 64)\n",
      "(1, 33, 34, 128)\n",
      "(1, 17, 17, 256)\n",
      "(1, 9, 9, 512)\n",
      "(1, 5, 5, 512)\n",
      "what??\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x504 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fileList = os.listdir(all_img_path)\n",
    "for img_path in fileList:\n",
    "    print(img_path)\n",
    "    img_path = all_img_path+'/'+img_path\n",
    "    print(img_path)\n",
    "\n",
    "    # 读取 内容图像\n",
    "    content_val = read_img(img_path)\n",
    "    print(content_val.shape)\n",
    "\n",
    "    content = tf.placeholder(tf.float32, shape = [1, 66, 67, 3])\n",
    "    print(content.shape)\n",
    "\n",
    "\n",
    "    # 载入模型， 注意：在python3中，需要添加一句： encoding='latin1'\n",
    "    data_dict = np.load(vgg16_npy_pyth,allow_pickle=True, encoding='latin1').item()\n",
    "\n",
    "\n",
    "    # 创建图像的 vgg 对象\n",
    "    vgg_for_content = VGGNet(data_dict)\n",
    "\n",
    "\n",
    "    # 创建 每个 神经网络\n",
    "    vgg_for_content.build(content)\n",
    "\n",
    "    content_features = [vgg_for_content.conv1_2,\n",
    "                        vgg_for_content.conv2_2,\n",
    "                        vgg_for_content.conv3_3,\n",
    "                        vgg_for_content.conv4_3,\n",
    "                        vgg_for_content.conv5_3,\n",
    "                        ]\n",
    "\n",
    "\n",
    "    #大概是tensorflow环境初始化的概念\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init_op)\n",
    "\n",
    "        #feed_dict的作用是给使用placeholder创建出来的tensor赋值\n",
    "        #真正的去执行整个提取过程，feed_dict是为之前定义好的变量（占位符）赋值，之前的content只是一个空的张量，    \n",
    "        #现在将图片的数据content_val赋值进去\n",
    "        content_features = sess.run([content_features],\n",
    "                     feed_dict = {\n",
    "                         content:content_val\n",
    "                     }) \n",
    "\n",
    "        conv1 = content_features[0][0]\n",
    "        conv2 = content_features[0][1]\n",
    "        conv3 = content_features[0][2]\n",
    "        conv4 = content_features[0][3]\n",
    "        conv5 = content_features[0][4]\n",
    "\n",
    "        print(conv1.shape)\n",
    "        print(conv2.shape)\n",
    "        print(conv3.shape)\n",
    "        print(conv4.shape)\n",
    "        print(conv5.shape)\n",
    "        # 查看 每个 特征 子图\n",
    "        visualize_feature_map(conv5)\n",
    "\n",
    "        # 查看 叠加后的 特征图\n",
    "        visualize_feature_map_sum(conv5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
